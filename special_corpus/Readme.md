In each subdirectory,
contains:
1). en and zh sentences (all together)
2). pos and neg line number (start from 1)
3). pos and neg sentences for en and zh

Some data are tokenized while some are not. Please retokenize everything if you want to use the corpus.

The multi embedding according to sentiment is achieved by special tokenization.
